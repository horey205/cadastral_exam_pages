
import json
import os
import time
import requests
import ssl
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from urllib.parse import urljoin

# ==========================================
# ì„¤ì • ì˜ì—­
# ==========================================
# ìŠ¤í¬ë˜í•‘í•  ëŒ€ìƒ ëª©ë¡ í˜ì´ì§€ (ì¸¡ëŸ‰ë°ì§€í˜•ê³µê°„ì •ë³´ì‚°ì—…ê¸°ì‚¬)
SUBJECT_URL = "https://www.kinz.kr/subject/9075"

# ë°ì´í„° ì €ì¥ ê²½ë¡œ (ë£¨íŠ¸ í´ë”)
# BASE_DIR = os.path.dirname(os.path.abspath(__file__)) # ê¸°ì¡´: ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜
ROOT_DIR = r"C:\AI_Class\ì¸¡ëŸ‰ìê²©ì¦ê¸°ì¶œë¬¸ì œ"
SURVEY_DATA_DIR = os.path.join(ROOT_DIR, "SurveyingExamData")  
IMAGE_DIR = os.path.join(SURVEY_DATA_DIR, "images")

# SSL ì¸ì¦ì„œ ë¬¸ì œ ìš°íšŒ ì„¤ì •
os.environ['WDM_SSL_VERIFY'] = '0'

if not os.path.exists(SURVEY_DATA_DIR):
    os.makedirs(SURVEY_DATA_DIR)
if not os.path.exists(IMAGE_DIR):
    os.makedirs(IMAGE_DIR)

# ==========================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ==========================================
def download_image(img_url, file_prefix):
    """ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ë¡œì»¬ ê²½ë¡œë¥¼ ë°˜í™˜"""
    if not img_url: return None
    try:
        # URL ì ˆëŒ€ê²½ë¡œ ë³€í™˜
        if not img_url.startswith('http'):
            img_url = "https://www.kinz.kr" + img_url
            
        # í™•ì¥ì ì¶”ì¶œ ë° íŒŒì¼ëª… ìƒì„± (ì¿¼ë¦¬ìŠ¤íŠ¸ë§ ì œê±°)
        ext = img_url.split('.')[-1].split('?')[0]
        if len(ext) > 4 or ext.lower() not in ['jpg', 'jpeg', 'png', 'gif']: 
            ext = 'jpg'
        
        filename = f"{file_prefix}.{ext}"
        save_path = os.path.join(IMAGE_DIR, filename)
        # JSONì— ì €ì¥ë  ê²½ë¡œëŠ” 'images/íŒŒì¼ëª…' (SurveyingData í´ë” ë‚´ë¶€ ê¸°ì¤€)
        relative_path = f"images/{filename}"
        
        # ì´ë¯¸ ì¡´ì¬í•˜ë©´ ë‹¤ìš´ë¡œë“œ ê±´ë„ˆë›°ê¸°
        if os.path.exists(save_path):
            return relative_path

        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (SSL ë¬´ì‹œ)
        response = requests.get(img_url, verify=False, timeout=10)
        if response.status_code == 200:
            with open(save_path, 'wb') as f:
                f.write(response.content)
            return relative_path
            
    except Exception as e:
        print(f"    [Image Error] {img_url}: {e}")
    return None

def init_driver():
    """í¬ë¡¬ ë“œë¼ì´ë²„ ì´ˆê¸°í™” ë° ì˜µì…˜ ì„¤ì •"""
    options = webdriver.ChromeOptions()
    options.add_argument('--headless') # ì°½ ì—†ì´ ì‹¤í–‰
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--ignore-certificate-errors')
    options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')
    
    # SSL Context Patch
    try:
        _create_unverified_https_context = ssl._create_unverified_context
    except AttributeError:
        pass
    else:
        ssl._create_default_https_context = _create_unverified_https_context

    # ë“œë¼ì´ë²„ ìë™ ì„¤ì¹˜ ë° ì‹¤í–‰
    service = Service(ChromeDriverManager().install())
    return webdriver.Chrome(service=service, options=options)

def get_exam_links(driver, subject_url):
    """ë©”ì¸ ëª©ë¡ í˜ì´ì§€ì—ì„œ ê° íšŒì°¨ë³„ ì‹œí—˜ URLì„ ìˆ˜ì§‘"""
    print(f"ğŸ“‚ ëª©ë¡ í˜ì´ì§€ ì ‘ì† ì¤‘: {subject_url}")
    driver.get(subject_url)
    time.sleep(3)
    
    links = []
    # ëª©ë¡ í˜ì´ì§€ì˜ êµ¬ì¡° ë¶„ì„ì„ í†µí•´ ë§í¬ ì¶”ì¶œ (kinz.kr êµ¬ì¡° ê¸°ë°˜)
    # 1. ì¼ë°˜ì ì¸ í…Œì´ë¸” êµ¬ì¡° ì‹œë„
    elems = driver.find_elements(By.CSS_SELECTOR, 'table tbody tr td.text-left a')
    
    # 2. ë§Œì•½ ìœ„ì—ì„œ ëª» ì°¾ìœ¼ë©´ ë‹¤ë¥¸ êµ¬ì¡° ì‹œë„ (ì˜ˆ: div ë¦¬ìŠ¤íŠ¸)
    if not elems:
        print("    -> ê¸°ë³¸ í…Œì´ë¸” êµ¬ì¡°ì—ì„œ ë§í¬ë¥¼ ì°¾ì§€ ëª»í•¨. ëŒ€ì²´ êµ¬ì¡° ê²€ìƒ‰...")
        elems = driver.find_elements(By.TAG_NAME, 'a')
    
    for el in elems:
        try:
            href = el.get_attribute('href')
            title = el.text.strip()
            # kinz.kr/exam/ ìˆ«ì íŒ¨í„´ì´ ìˆëŠ” ë§í¬ë§Œ ìœ íš¨í•œ ì‹œí—˜ì§€ ë§í¬
            if href and ('/exam/' in href) and title:
                # ì¤‘ë³µ ë°©ì§€
                if not any(l['url'] == href for l in links):
                     links.append({'title': title, 'url': href})
        except:
             continue
            
    print(f"âœ… ì´ {len(links)}ê°œì˜ ì‹œí—˜ íšŒì°¨ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
    return links

def scrape_single_exam(driver, url, exam_title):
    """ë‹¨ì¼ íšŒì°¨ í˜ì´ì§€ ìŠ¤í¬ë˜í•‘"""
    print(f"  â–¶ ìŠ¤í¬ë˜í•‘ ì‹œì‘: {exam_title}")
    driver.get(url)
    time.sleep(2)

    # 1. ì •ë‹µ ë³´ê¸° ë²„íŠ¼ ì „ì²´ í´ë¦­ (ìˆ¨ê²¨ì§„ ì •ë‹µ/í•´ì„¤ ë…¸ì¶œ)
    try:
        driver.execute_script("document.querySelectorAll('.show-answer').forEach(b => b.click())")
        time.sleep(1.5) # ë Œë”ë§ ëŒ€ê¸°
    except Exception as e:
        print(f"    [Wiki] ë²„íŠ¼ í´ë¦­ ì‹¤íŒ¨(ì´ë¯¸ ì—´ë ¤ìˆê±°ë‚˜ ì—†ìŒ): {e}")

    # 2. ë°ì´í„° ì¶”ì¶œ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
    # (ì´ë¯¸ì§€, ë³´ê¸°, ì •ë‹µ, í•´ì„¤ í¬í•¨)
    extraction_script = r"""
        const result = [];
        const questions = document.querySelectorAll('.exam-question');
        
        questions.forEach((div, idx) => {
            const qObj = {};
            
            // 1. ë¬¸ì œ í…ìŠ¤íŠ¸ ë° ì œëª©
            const h5 = div.querySelector('h5');
            if(!h5) return;
            
            let rawText = h5.innerText.trim();
            // "1. ë¬¸ì œë‚´ìš©..." í˜•ì‹ì´ë¯€ë¡œ ë²ˆí˜¸ ì œê±° ì‹œë„
            rawText = rawText.replace(/^\d+\.\s*/, '');
            qObj.text = rawText.split('\n')[0]; // ì²« ì¤„ë§Œ ì œëª©ìœ¼ë¡œ ì‚¬ìš©
            
            // ê³¼ëª© ì¶”ì¶œ (í…ìŠ¤íŠ¸ ë‚´ 'ê³¼ëª© :' ì°¾ê¸°)
            qObj.subject = "ê¸°íƒ€";
            const subjectMatch = rawText.match(/ê³¼ëª©\s*:\s*([^\n]+)/);
            if(subjectMatch) qObj.subject = subjectMatch[1].trim();

            // 2. ì´ë¯¸ì§€ URL ìˆ˜ì§‘
            // h5 ë‚´ë¶€ + ë³´ê¸°ê°€ ë‚˜ì˜¤ê¸° ì „ê¹Œì§€ì˜ í˜•ì œ ìš”ì†Œë“¤
            let imgUrls = [];
            
            // (1) h5 ë‚´ë¶€
            h5.querySelectorAll('img').forEach(img => imgUrls.push(img.getAttribute('src')));
            
            // (2) í˜•ì œ ìš”ì†Œ ìŠ¤ìº”
            let sibling = h5.nextElementSibling;
            while(sibling && sibling.tagName !== 'UL' && sibling.tagName !== 'H5' && !sibling.classList.contains('exam-explanation')) {
                if(sibling.tagName === 'IMG') {
                     imgUrls.push(sibling.getAttribute('src'));
                } else {
                     sibling.querySelectorAll('img').forEach(img => imgUrls.push(img.getAttribute('src')));
                }
                sibling = sibling.nextElementSibling;
            }
            qObj.images = imgUrls;

            // 3. ë³´ê¸° ì¶”ì¶œ
            qObj.options = [];
            const ul = div.querySelector('ul');
            if(ul) {
                ul.querySelectorAll('li').forEach(li => {
                    let optText = li.innerText.replace(/^[â‘ â‘¡â‘¢â‘£]/, '').trim();
                    // ë³´ê¸° ë‚´ ì´ë¯¸ì§€ ì²˜ë¦¬
                    li.querySelectorAll('img').forEach(img => {
                       optText += ` [IMG:${img.getAttribute('src')}]`;
                    });
                    qObj.options.push(optText);
                });
            }

            // 4. ì •ë‹µ ì¶”ì¶œ
            // ë²„íŠ¼ í´ë¦­ í›„ ë‚˜íƒ€ë‚œ í…ìŠ¤íŠ¸ì—ì„œ íŒŒì‹±
            qObj.answer = 0;
            if(div.innerText.includes('ì •ë‹µ :')) {
                 const m = div.innerText.match(/ì •ë‹µ\s*:\s*(\d)/);
                 if(m) qObj.answer = parseInt(m[1]);
            } else if(div.innerText.includes('ì •ë‹µ:')) {
                 const m = div.innerText.match(/ì •ë‹µ:\s*(\d)/);
                 if(m) qObj.answer = parseInt(m[1]);
            }

            // 5. í•´ì„¤ ì¶”ì¶œ
            qObj.explanation = "";
            const expDiv = div.querySelector('.exam-explanation');
            // í•´ì„¤ì´ ìˆê³ , display: noneì´ ì•„ë‹ˆì–´ì•¼ í•¨ (í˜¹ì€ í…ìŠ¤íŠ¸ê°€ ìˆì–´ì•¼ í•¨)
            if(expDiv && expDiv.innerText.trim().length > 0) {
                 qObj.explanation = expDiv.innerText.trim();
                 // í•´ì„¤ ë‚´ ì´ë¯¸ì§€
                 expDiv.querySelectorAll('img').forEach(img => {
                     qObj.explanation += ` [IMG:${img.getAttribute('src')}]`;
                 });
            }

            result.push(qObj);
        });
        return result;
    """
    
    raw_questions = driver.execute_script(extraction_script)
    
    processed_questions = []
    for idx, q in enumerate(raw_questions):
        # ê³ ìœ  ID ìƒì„± (íšŒì°¨_ë²ˆí˜¸)
        # íŒŒì¼ ì‹œìŠ¤í…œ ì¹œí™”ì ì¸ IDë¡œ ë³€ê²½ (íŠ¹ìˆ˜ë¬¸ì ì œê±°)
        safe_title = "".join(x for x in exam_title if x.isalnum())
        q_id = f"{safe_title}_{idx+1}"
        
        q['id'] = q_id
        q['source'] = exam_title
        
        # ë©”ì¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        local_imgs = []
        for i, img_src in enumerate(q['images']):
            local_path = download_image(img_src, f"{q_id}_img_{i}")
            if local_path:
                local_imgs.append(local_path)
        q['local_images'] = local_imgs
        # ì›ë³¸ URL ì œê±° (ìš©ëŸ‰ ì ˆì•½)
        del q['images']

        # í•´ì„¤ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (í…ìŠ¤íŠ¸ ë‚´ ì¹˜í™˜)
        if '[IMG:' in q['explanation']:
            parts = q['explanation'].split('[IMG:')
            new_exp = parts[0]
            for p_idx, p in enumerate(parts[1:]):
                src_part = p.split(']')[0]
                rest_part = p.split(']')[1]
                
                loc = download_image(src_part, f"{q_id}_exp_{p_idx}")
                if loc:
                    new_exp += f"<br><img src='{loc}' class='exp-img'><br>"
                else:
                    new_exp += "(ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨)"
                new_exp += rest_part
            q['explanation'] = new_exp

        processed_questions.append(q)
        
    print(f"    - ë¬¸í•­ ìˆ˜: {len(processed_questions)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
    return processed_questions

# ==========================================
# ë©”ì¸ ì‹¤í–‰ ë¡œì§
# ==========================================
def main():
    driver = init_driver()
    all_data = []

    try:
        # 1. ëª©ë¡ ìˆ˜ì§‘
        links = get_exam_links(driver, SUBJECT_URL)
        
        # ì „ì²´ íšŒì°¨ ìˆ˜ì§‘ (ì œí•œ í•´ì œ)
        target_links = links 
        print(f"ğŸš€ ì „ì²´ {len(target_links)}ê°œ íšŒì°¨ì— ëŒ€í•´ ìŠ¤í¬ë˜í•‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        
        # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ (ì¤‘ë³µ ë°©ì§€ìš©)
        existing_ids = set()
        # SurveyingData í´ë” ë‚´ì˜ ëª¨ë“  json ì½ì–´ì˜¤ê¸°
        for fname in os.listdir(SURVEY_DATA_DIR):
            if fname.endswith('.json'):
                try:
                    with open(os.path.join(SURVEY_DATA_DIR, fname), 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        for item in data:
                            existing_ids.add(item.get('id'))
                except: pass
        
        print(f"    (ì´ë¯¸ ìˆ˜ì§‘ëœ ë¬¸ì œ ìˆ˜: {len(existing_ids)}ê°œ - ì¤‘ë³µ íšŒì°¨ëŠ” ê±´ë„ˆëœë‹ˆë‹¤)")

        for exam in target_links:
            try:
                # íšŒì°¨ëª…ìœ¼ë¡œ ì´ë¯¸ ìˆ˜ì§‘ ì—¬ë¶€ íŒë‹¨ì€ ì–´ë ¤ìš°ë¯€ë¡œ(IDê°€ ê°œë³„ ë¬¸ì œë‹¨ìœ„), 
                # ì¼ë‹¨ ì ‘ì†í•´ì„œ ì²« ë¬¸ì œ IDê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê±°ë‚˜, ê·¸ëƒ¥ ë®ì–´ì“°ê¸° ëª¨ë“œë¡œ ì§„í–‰.
                # ì—¬ê¸°ì„œëŠ” ì•ˆì „í•˜ê²Œ ì „ì²´ ìˆœíšŒí•˜ë˜, ë‹¤ìš´ë¡œë“œ ë¶€í•˜ë§Œ ì¤„ì„.
                
                print(f"  â–¶ ì§„í–‰ ì¤‘: {exam['title']}")
                questions = scrape_single_exam(driver, exam['url'], exam['title'])
                
                # ìˆ˜ì§‘ëœ ë°ì´í„° ë³‘í•©
                all_data.extend(questions)
                
                # ì¤‘ê°„ ì €ì¥ (í˜¹ì‹œ ëª¨ë¥¼ ì¤‘ë‹¨ ëŒ€ë¹„: ì„ì‹œ íŒŒì¼)
                temp_file = os.path.join(SURVEY_DATA_DIR, "temp_progress.json")
                with open(temp_file, 'w', encoding='utf-8') as f:
                    json.dump(all_data, f, ensure_ascii=False, indent=2)
                    
                time.sleep(1) # ì„œë²„ ë¶€í•˜ ë°©ì§€
            except Exception as e:
                print(f"    [Error] {exam['title']} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

        # ê³¼ëª©ë³„ë¡œ ë°ì´í„° ë¶„ë¥˜
        subject_data = {}
        for q in all_data:
            subj = q.get('subject', 'ê¸°íƒ€')
            # íŒŒì¼ëª…ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°
            safe_subj = "".join(x for x in subj if x.isalnum() or x in (' ', '_', '-')).strip()
            if not safe_subj: safe_subj = "ê¸°íƒ€_ë¯¸ë¶„ë¥˜"
            
            if safe_subj not in subject_data:
                subject_data[safe_subj] = []
            subject_data[safe_subj].append(q)

        # ê³¼ëª©ë³„ JSON íŒŒì¼ ì €ì¥
        print(f"\nğŸ’¾ ê³¼ëª©ë³„ íŒŒì¼ ì €ì¥ ì¤‘...")
        for subj, q_list in subject_data.items():
            # íŒŒì¼ëª… ì •ë¦¬
            safe_subj = "".join(x for x in subj if x.isalnum() or x in (' ', '_', '-')).strip()
            if not safe_subj: safe_subj = "ê¸°íƒ€_ë¯¸ë¶„ë¥˜"
            
            filename = f"{safe_subj}.json"
            # ë³€ê²½ëœ ì €ì¥ ê²½ë¡œ (SurveyingData í´ë”)
            filepath = os.path.join(SURVEY_DATA_DIR, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(q_list, f, ensure_ascii=False, indent=2)
            print(f"  - {filename}: {len(q_list)} ë¬¸ì œ ì €ì¥ ì™„ë£Œ (-> {SURVEY_DATA_DIR})")
            
        print(f"\nâœ¨ ì „ì²´ ì‘ì—… ì™„ë£Œ! ì´ {len(all_data)}ê°œì˜ ë¬¸ì œë¥¼ ìˆ˜ì§‘í•˜ì—¬ ê³¼ëª©ë³„ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        driver.quit()

if __name__ == "__main__":
    main()
