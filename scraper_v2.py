
import json
import os
import time
import requests
import ssl
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from urllib.parse import urljoin

# ==========================================
# ì„¤ì • ì˜ì—­
# ==========================================
# ìŠ¤í¬ë˜í•‘í•  ëŒ€ìƒ ëª©ë¡ í˜ì´ì§€ (ì§€ì ì‚°ì—…ê¸°ì‚¬: 8636)
SUBJECT_URL = "https://www.kinz.kr/subject/8636"

# ë°ì´í„° ì €ì¥ ê²½ë¡œ
current_dir = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(current_dir, "data")
IMAGE_DIR = os.path.join(DATA_DIR, "images")

if not os.path.exists(DATA_DIR):
    os.makedirs(DATA_DIR)
if not os.path.exists(IMAGE_DIR):
    os.makedirs(IMAGE_DIR)

# SSL ì¸ì¦ì„œ ë¬¸ì œ ìš°íšŒ ì„¤ì •
os.environ['WDM_SSL_VERIFY'] = '0'

# ==========================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ==========================================
def download_image(img_url, file_prefix):
    """ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ë¡œì»¬ ê²½ë¡œë¥¼ ë°˜í™˜"""
    if not img_url: return None
    try:
        # URL ì ˆëŒ€ê²½ë¡œ ë³€í™˜
        if not img_url.startswith('http'):
            img_url = "https://www.kinz.kr" + img_url
            
        # í™•ì¥ì ì¶”ì¶œ ë° íŒŒì¼ëª… ìƒì„± (ì¿¼ë¦¬ìŠ¤íŠ¸ë§ ì œê±°)
        ext = img_url.split('.')[-1].split('?')[0]
        if len(ext) > 4 or ext.lower() not in ['jpg', 'jpeg', 'png', 'gif']: 
            ext = 'jpg'
        
        filename = f"{file_prefix}.{ext}"
        save_path = os.path.join(IMAGE_DIR, filename)
        # JSONì— ì €ì¥ë  ê²½ë¡œëŠ” 'data/images/íŒŒì¼ëª…'ì´ ì•„ë‹ˆë¼
        # ë‚˜ì¤‘ì— ì›¹ ì•±ì—ì„œ 'images/íŒŒì¼ëª…'ìœ¼ë¡œ ì ‘ê·¼í•  ìˆ˜ ìˆê²Œ ìƒëŒ€ ê²½ë¡œë¡œ ì €ì¥
        # ë‹¨, ì—¬ê¸°ì„œëŠ” output JSON êµ¬ì¡°ìƒ 'images/filename'ìœ¼ë¡œ ì €ì¥
        relative_path = f"images/{filename}"
        
        # ì´ë¯¸ ì¡´ì¬í•˜ë©´ ë‹¤ìš´ë¡œë“œ ê±´ë„ˆë›°ê¸°
        if os.path.exists(save_path):
            return relative_path

        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (SSL ë¬´ì‹œ)
        response = requests.get(img_url, verify=False, timeout=10)
        if response.status_code == 200:
            with open(save_path, 'wb') as f:
                f.write(response.content)
            return relative_path
            
    except Exception as e:
        print(f"    [Image Error] {img_url}: {e}")
    return None

def init_driver():
    """í¬ë¡¬ ë“œë¼ì´ë²„ ì´ˆê¸°í™” ë° ì˜µì…˜ ì„¤ì •"""
    options = webdriver.ChromeOptions()
    options.add_argument('--headless') # ì°½ ì—†ì´ ì‹¤í–‰
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--ignore-certificate-errors')
    options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')
    
    # SSL Context Patch
    try:
        _create_unverified_https_context = ssl._create_unverified_context
    except AttributeError:
        pass
    else:
        ssl._create_default_https_context = _create_unverified_https_context

    # ë“œë¼ì´ë²„ ìë™ ì„¤ì¹˜ ë° ì‹¤í–‰
    service = Service(ChromeDriverManager().install())
    return webdriver.Chrome(service=service, options=options)

def get_exam_links(driver, subject_url):
    """ë©”ì¸ ëª©ë¡ í˜ì´ì§€ì—ì„œ ê° íšŒì°¨ë³„ ì‹œí—˜ URLì„ ìˆ˜ì§‘"""
    print(f"ğŸ“‚ ëª©ë¡ í˜ì´ì§€ ì ‘ì† ì¤‘: {subject_url}")
    driver.get(subject_url)
    time.sleep(3)
    
    links = []
    # ëª©ë¡ í˜ì´ì§€ì˜ êµ¬ì¡° ë¶„ì„ì„ í†µí•´ ë§í¬ ì¶”ì¶œ (kinz.kr êµ¬ì¡° ê¸°ë°˜)
    # 1. ì¼ë°˜ì ì¸ í…Œì´ë¸” êµ¬ì¡° ì‹œë„
    elems = driver.find_elements(By.CSS_SELECTOR, 'table tbody tr td.text-left a')
    
    # 2. ë§Œì•½ ìœ„ì—ì„œ ëª» ì°¾ìœ¼ë©´ ë‹¤ë¥¸ êµ¬ì¡° ì‹œë„ (ì˜ˆ: div ë¦¬ìŠ¤íŠ¸)
    if not elems:
        print("    -> ê¸°ë³¸ í…Œì´ë¸” êµ¬ì¡°ì—ì„œ ë§í¬ë¥¼ ì°¾ì§€ ëª»í•¨. ëŒ€ì²´ êµ¬ì¡° ê²€ìƒ‰...")
        elems = driver.find_elements(By.TAG_NAME, 'a')
    
    for el in elems:
        try:
            href = el.get_attribute('href')
            title = el.text.strip()
            # kinz.kr/exam/ ìˆ«ì íŒ¨í„´ì´ ìˆëŠ” ë§í¬ë§Œ ìœ íš¨í•œ ì‹œí—˜ì§€ ë§í¬
            if href and ('/exam/' in href) and title:
                # ì¤‘ë³µ ë°©ì§€
                if not any(l['url'] == href for l in links):
                     links.append({'title': title, 'url': href})
        except:
             continue
            
    print(f"âœ… ì´ {len(links)}ê°œì˜ ì‹œí—˜ íšŒì°¨ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
    return links

def scrape_single_exam(driver, url, exam_title):
    """ë‹¨ì¼ íšŒì°¨ í˜ì´ì§€ ìŠ¤í¬ë˜í•‘"""
    print(f"  â–¶ ìŠ¤í¬ë˜í•‘ ì‹œì‘: {exam_title}")
    driver.get(url)
    time.sleep(3)

    # 1. ì •ë‹µ ë³´ê¸° ë²„íŠ¼ ì „ì²´ í´ë¦­ (ìˆ¨ê²¨ì§„ ì •ë‹µ/í•´ì„¤ ë…¸ì¶œ)
    try:
        driver.execute_script("document.querySelectorAll('.show-answer').forEach(b => b.click())")
        time.sleep(2) # ë Œë”ë§ ëŒ€ê¸°
    except Exception as e:
        print(f"    [Wiki] ë²„íŠ¼ í´ë¦­ ì‹¤íŒ¨(ì´ë¯¸ ì—´ë ¤ìˆê±°ë‚˜ ì—†ìŒ): {e}")

    # 2. ë°ì´í„° ì¶”ì¶œ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
    extraction_script = r"""
        const result = [];
        const questions = document.querySelectorAll('.exam-question');
        
        questions.forEach((div, idx) => {
            const qObj = {};
            
            // 1. ë¬¸ì œ í…ìŠ¤íŠ¸ ë° ì œëª©
            const h5 = div.querySelector('h5');
            if(!h5) return;
            
            let rawText = h5.innerText.trim();
            rawText = rawText.replace(/^\d+\.\s*/, '');
            qObj.text = rawText.split('\n')[0]; // ì²« ì¤„ë§Œ ì œëª©ìœ¼ë¡œ ì‚¬ìš©
            
            // ê³¼ëª© ì¶”ì¶œ
            qObj.subject = "ê¸°íƒ€";
            const subjectMatch = rawText.match(/ê³¼ëª©\s*:\s*([^\n]+)/);
            if(subjectMatch) qObj.subject = subjectMatch[1].trim();

            // 2. ì´ë¯¸ì§€ URL ìˆ˜ì§‘
            let imgUrls = [];
            h5.querySelectorAll('img').forEach(img => imgUrls.push(img.getAttribute('src')));
            
            let sibling = h5.nextElementSibling;
            while(sibling && sibling.tagName !== 'UL' && sibling.tagName !== 'H5' && !sibling.classList.contains('exam-explanation')) {
                if(sibling.tagName === 'IMG') {
                     imgUrls.push(sibling.getAttribute('src'));
                } else {
                     sibling.querySelectorAll('img').forEach(img => imgUrls.push(img.getAttribute('src')));
                }
                sibling = sibling.nextElementSibling;
            }
            qObj.images = imgUrls;

            // 3. ë³´ê¸° ì¶”ì¶œ
            qObj.options = [];
            const ul = div.querySelector('ul');
            if(ul) {
                ul.querySelectorAll('li').forEach(li => {
                    let optText = li.innerText.replace(/^[â‘ â‘¡â‘¢â‘£]/, '').trim();
                    li.querySelectorAll('img').forEach(img => {
                       optText += ` [IMG:${img.getAttribute('src')}]`;
                    });
                    qObj.options.push(optText);
                });
            }

            // 4. ì •ë‹µ ì¶”ì¶œ
            qObj.answer = 0;
            if(div.innerText.includes('ì •ë‹µ :')) {
                 const m = div.innerText.match(/ì •ë‹µ\s*:\s*(\d)/);
                 if(m) qObj.answer = parseInt(m[1]);
            } else if(div.innerText.includes('ì •ë‹µ:')) {
                 const m = div.innerText.match(/ì •ë‹µ:\s*(\d)/);
                 if(m) qObj.answer = parseInt(m[1]);
            }

            // 5. í•´ì„¤ ì¶”ì¶œ
            qObj.explanation = "";
            const expDiv = div.querySelector('.exam-explanation');
            if(expDiv && expDiv.innerText.trim().length > 0) {
                 qObj.explanation = expDiv.innerText.trim();
                 expDiv.querySelectorAll('img').forEach(img => {
                     qObj.explanation += ` [IMG:${img.getAttribute('src')}]`;
                 });
            }

            result.push(qObj);
        });
        return result;
    """
    
    raw_questions = driver.execute_script(extraction_script)
    
    processed_questions = []
    for idx, q in enumerate(raw_questions):
        safe_title = "".join(x for x in exam_title if x.isalnum())
        q_id = f"{safe_title}_{idx+1}"
        
        q['id'] = q_id
        q['source'] = exam_title
        
        # ë©”ì¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        local_img = None
        # Use first image as main image if exists
        if len(q['images']) > 0:
            local_img = download_image(q['images'][0], f"{q_id}_img_main")
        
        q['image'] = local_img # ì•± í˜¸í™˜ì„±ì„ ìœ„í•´ single image í•„ë“œ ì‚¬ìš©
        # (ë§Œì•½ ì—¬ëŸ¬ê°œë©´ ë¬´ì‹œë˜ê±°ë‚˜ ì¶”ê°€ ì²˜ë¦¬ê°€ í•„ìš”í•˜ì§€ë§Œ ë³´í†µ 1ê°œ)
        
        del q['images']

        # ë³´ê¸° ë‚´ ì´ë¯¸ì§€ ì²˜ë¦¬
        new_opts = []
        for opt_idx, opt in enumerate(q['options']):
            if '[IMG:' in opt:
                parts = opt.split('[IMG:')
                new_opt = parts[0]
                for p_idx, p in enumerate(parts[1:]):
                    src_part = p.split(']')[0]
                    rest_part = p.split(']')[1]
                    loc = download_image(src_part, f"{q_id}_opt_{opt_idx}_{p_idx}")
                    if loc:
                        new_opt += f"<br><img src='{loc}' class='opt-img'>"
                    new_opt += rest_part
                new_opts.append(new_opt)
            else:
                new_opts.append(opt)
        q['options'] = new_opts

        # í•´ì„¤ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        if '[IMG:' in q['explanation']:
            parts = q['explanation'].split('[IMG:')
            new_exp = parts[0]
            for p_idx, p in enumerate(parts[1:]):
                src_part = p.split(']')[0]
                rest_part = p.split(']')[1]
                loc = download_image(src_part, f"{q_id}_exp_{p_idx}")
                if loc:
                    new_exp += f"<br><img src='{loc}' class='exp-img'><br>"
                new_exp += rest_part
            q['explanation'] = new_exp

        processed_questions.append(q)
        
    print(f"    - ë¬¸í•­ ìˆ˜: {len(processed_questions)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
    return processed_questions

def main():
    driver = init_driver()
    all_data = []

    try:
        # 1. ëª©ë¡ ìˆ˜ì§‘
        links = get_exam_links(driver, SUBJECT_URL)
        print(f"ğŸš€ ì „ì²´ {len(links)}ê°œ íšŒì°¨ì— ëŒ€í•´ ìŠ¤í¬ë˜í•‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        
        for exam in links:
            try:
                print(f"  â–¶ ì§„í–‰ ì¤‘: {exam['title']}")
                questions = scrape_single_exam(driver, exam['url'], exam['title'])
                all_data.extend(questions)
                time.sleep(1) 
            except Exception as e:
                print(f"    [Error] {exam['title']} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

        # ëª¨ë“  ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ íŒŒì¼ì— ì €ì¥ (json)
        # ë‚˜ì¤‘ì— questions.jsë¡œ ë³€í™˜í•˜ê¸° ì‰¬ì›€
        OUTPUT_FILE = os.path.join(DATA_DIR, "all_questions.json")
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            json.dump(all_data, f, ensure_ascii=False, indent=2)
            
        print(f"\nâœ¨ ì „ì²´ ì‘ì—… ì™„ë£Œ! ì´ {len(all_data)}ê°œì˜ ë¬¸ì œë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
        print(f"ì €ì¥ ìœ„ì¹˜: {OUTPUT_FILE}")
        
        # JS ë³€í™˜ (ë°”ë¡œ ì•±ì—ì„œ ì“¸ ìˆ˜ ìˆê²Œ)
        questions_js_path = os.path.join(current_dir, "questions.js")
        with open(questions_js_path, 'w', encoding='utf-8') as f:
            f.write("const questionData = " + json.dumps(all_data, indent=2, ensure_ascii=False) + ";")
        print(f"JS íŒŒì¼ ìƒì„± ì™„ë£Œ: {questions_js_path}")

    except Exception as e:
        print(f"ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        driver.quit()

if __name__ == "__main__":
    main()
